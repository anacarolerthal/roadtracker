{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import col, row_number, countDistinct\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"HistoricalRoadTracker\") \\\n",
    "    .config(\"spark.driver.memory\", \"8g\") \\\n",
    "    .config(\"spark.executor.cores\", \"4\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/c:/Users/Carol Erthal/Documents/fgv/5P/COMP_ESCALAVEL/roadtracker/etl/all_roads.csv.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Carol Erthal\\Documents\\fgv\\5P\\COMP_ESCALAVEL\\roadtracker\\etl\\historical_analysis.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/5P/COMP_ESCALAVEL/roadtracker/etl/historical_analysis.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# load the data\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Carol%20Erthal/Documents/fgv/5P/COMP_ESCALAVEL/roadtracker/etl/historical_analysis.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mcsv(\u001b[39m\"\u001b[39;49m\u001b[39mall_roads.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, inferSchema\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\Carol Erthal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\sql\\readwriter.py:727\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[1;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[0;32m    726\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spark\u001b[39m.\u001b[39m_sc\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 727\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mcsv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_spark\u001b[39m.\u001b[39;49m_sc\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonUtils\u001b[39m.\u001b[39;49mtoSeq(path)))\n\u001b[0;32m    728\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, RDD):\n\u001b[0;32m    730\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(iterator):\n",
      "File \u001b[1;32mc:\\Users\\Carol Erthal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[0;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Carol Erthal\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:175\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    171\u001b[0m converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n\u001b[0;32m    172\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    173\u001b[0m     \u001b[39m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[39m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m converted \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m    176\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    177\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/c:/Users/Carol Erthal/Documents/fgv/5P/COMP_ESCALAVEL/roadtracker/etl/all_roads.csv."
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "df = spark.read.csv(\"all_roads.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|plate|road_count|\n",
      "+-----+----------+\n",
      "|SF428|         1|\n",
      "|TW315|         1|\n",
      "|JL736|         1|\n",
      "|EP171|         1|\n",
      "|PB094|         1|\n",
      "|MD954|         1|\n",
      "|ZZ212|         1|\n",
      "|ZP226|         1|\n",
      "|UN926|         1|\n",
      "|GF380|         1|\n",
      "|DT049|         1|\n",
      "|LI295|         1|\n",
      "|GB081|         1|\n",
      "|NP659|         1|\n",
      "|BK572|         1|\n",
      "|HI030|         1|\n",
      "|VF070|         1|\n",
      "|OG955|         1|\n",
      "|UX361|         1|\n",
      "|ZP642|         1|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# historical 1\n",
    "dfRoadCount = df.groupBy(\"plate\").agg(countDistinct('road')).withColumnRenamed(\"count(road)\", \"road_count\")\n",
    "\n",
    "# get the top 100\n",
    "dfRoadCount = dfRoadCount.orderBy(col(\"road_count\").desc()).limit(100)\n",
    "dfRoadCount.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+---------+---+---+-----+--------------------+---------+-----+---+\n",
      "| road|road_speed|road_size|  x|  y|plate|                time|direction|speed|acc|\n",
      "+-----+----------+---------+---+---+-----+--------------------+---------+-----+---+\n",
      "|road3|       120|     1000|220|  2|AC272| 1.686422274283066E9|        1|    0|  0|\n",
      "|road3|       120|     1000|220|  2|AC272|1.6864222536890728E9|        1|    0|  0|\n",
      "|road3|       120|     1000|220|  2|AC272| 1.686422231388323E9|        1|    0|  0|\n",
      "|road3|       120|     1000|220|  2|AC272|1.6864222095374138E9|        1|    0|  0|\n",
      "|road3|       120|     1000|220|  2|AC272|  1.68642220938139E9|        1|    0|  0|\n",
      "|road3|       120|     1000|220|  2|AC272|1.6864222092032158E9|        1|    0|-35|\n",
      "|road3|       120|     1000|220|  2|AC272|1.6864222087273128E9|        1|   35|-26|\n",
      "|road3|       120|     1000|185|  2|AC272|1.6864221860634181E9|        1|   61| -1|\n",
      "|road3|       120|     1000|331|  9|AU218| 1.686422286230809E9|       -1|   72|  2|\n",
      "|road3|       120|     1000|403|  9|AU218| 1.686422263140699E9|       -1|   70|  0|\n",
      "|road3|       120|     1000|473|  9|AU218|1.6864222420804741E9|       -1|   70|  0|\n",
      "|road3|       120|     1000|543|  9|AU218| 1.686422219653634E9|       -1|   70| -2|\n",
      "|road3|       120|     1000|613|  9|AU218| 1.686422197781182E9|       -1|   72| -5|\n",
      "|road3|       120|     1000|685|  9|AU218| 1.686422178944038E9|       -1|   77| -3|\n",
      "|road3|       120|     1000|762|  9|AU218| 1.686422164655915E9|       -1|   80|  1|\n",
      "|road1|       120|     1000|802|  8|AU372| 1.686422266813969E9|       -1|    0|  0|\n",
      "|road1|       120|     1000|802|  8|AU372| 1.686422245239255E9|       -1|    0|  0|\n",
      "|road1|       120|     1000|802|  8|AU372|1.6864222233056152E9|       -1|    0|  0|\n",
      "|road1|       120|     1000|802|  8|AU372| 1.686422202897731E9|       -1|    0|-85|\n",
      "|road1|       120|     1000|802|  8|AU372| 1.686422202422852E9|       -1|   85| 85|\n",
      "+-----+----------+---------+---+---+-----+--------------------+---------+-----+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CALCULATE SPEED AND ACCELERATION\n",
    "\n",
    "# calculate all speeds achieved by each car\n",
    "windowDept = Window.partitionBy(\"plate\").orderBy(col(\"time\").desc())\n",
    "dfCalcs = df.withColumn(\"row\",row_number().over(windowDept))\n",
    "\n",
    "# calc all speeds\n",
    "dfCalcs = dfCalcs.withColumn(\"speed\", F.col(\"x\") - F.lag(\"x\", -1).over(windowDept))\n",
    "\n",
    "# make all values positive\n",
    "dfCalcs = dfCalcs.withColumn(\"speed\", F.abs(F.col(\"speed\")))\n",
    "\n",
    "# calc all accs\n",
    "dfCalcs = dfCalcs.withColumn(\"acc\", F.col(\"speed\") - F.lag(\"speed\", -1).over(windowDept))\n",
    "\n",
    "# drop nulls and row column\n",
    "dfCalcs = dfCalcs.na.drop()\n",
    "dfCalcs = dfCalcs.drop(\"row\")\n",
    "\n",
    "dfCalcs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(road='road2', avg_speed=35.96995708154506, avg_time_to_cross=27.8009784035318, total_collisions=96),\n",
       " Row(road='road4', avg_speed=53.53777777777778, avg_time_to_cross=18.678399468703304, total_collisions=61),\n",
       " Row(road='road1', avg_speed=42.77439024390244, avg_time_to_cross=23.378474697077692, total_collisions=59),\n",
       " Row(road='road0', avg_speed=32.415929203539825, avg_time_to_cross=30.849030849030846, total_collisions=87),\n",
       " Row(road='road3', avg_speed=60.224, avg_time_to_cross=16.604675876726887, total_collisions=30)]"
      ]
     },
     "execution_count": 646,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# historical 2\n",
    "\n",
    "# get average speed per road\n",
    "dfStats = dfCalcs.groupBy(\"road\").avg(\"speed\", \"road_size\")\\\n",
    "            .withColumnRenamed(\"avg(speed)\", \"avg_speed\")\\\n",
    "            .withColumnRenamed(\"avg(road_size)\", \"road_size\")\n",
    "\n",
    "# calculate avg time to cross\n",
    "dfStats = dfStats.withColumn(\"avg_time_to_cross\", F.col( \"road_size\") / F.col(\"avg_speed\")).drop(\"road_size\")\n",
    "\n",
    "# get rows where speed = 0 and acc = 0 (collisions)\n",
    "dfCollisions = dfCalcs.filter((F.col(\"speed\") == 0) & (F.col(\"acc\") == 0))\n",
    "\n",
    "# group by road and count\n",
    "dfCollisions = dfCollisions.groupBy(\"road\").count().withColumnRenamed(\"count\", \"total_collisions\")\n",
    "\n",
    "# join the dataframes to get all stats\n",
    "dfStats = dfStats.join(dfCollisions, \"road\", \"left\")\n",
    "\n",
    "dfStats.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|plate|total_infractions|\n",
      "+-----+-----------------+\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# historical 3\n",
    "\n",
    "# partition by plate and order by time (twice to have ascending and descending row numbers)\n",
    "windowDept = Window.partitionBy(\"plate\").orderBy(col(\"time\").desc())\n",
    "windowDept2 = Window.partitionBy(\"plate\").orderBy(col(\"time\").asc())\n",
    "\n",
    "# create rows columns\n",
    "dfSpeeds = dfCalcs.withColumn(\"row\",row_number().over(windowDept))\n",
    "dfSpeeds = dfSpeeds.withColumn(\"row2\",row_number().over(windowDept2))\n",
    "\n",
    "# check where speed is greater than 120 and the previous speed was less than road_speed (that is, new infraction)\n",
    "dfSpeeds = dfSpeeds.withColumn(\"change_in_speed\",\n",
    "                   F.when(((F.col(\"speed\") > F.col(\"road_speed\")) & (F.lag(\"speed\", -1).over(windowDept) <= F.lag(\"road_speed\", -1).over(windowDept) )) , 1) \\\n",
    "                   .otherwise(0))\n",
    "\n",
    "# check for vehicles that enter a road with speed > road_speed (infraction)\n",
    "dfSpeeds = dfSpeeds.withColumn(\"change_in_speed\",\n",
    "                     F.when(((F.col(\"speed\") > F.col(\"road_speed\")) & (F.col(\"row2\") ==1)), 1) \\\n",
    "                        .otherwise(F.col(\"change_in_speed\")))\n",
    "\n",
    "# chosen T (change it after testing)\n",
    "t = 25000\n",
    "\n",
    "# get all rows where now() - time < t\n",
    "dfSpeeds = dfSpeeds.withColumn(\"past_time\", F.unix_timestamp(F.current_timestamp()).cast(\"double\"))\n",
    "dfSpeeds = dfSpeeds.withColumn(\"diff_time\", F.col(\"past_time\") - F.col(\"time\"))\n",
    "dfSpeeds = dfSpeeds.filter(F.col(\"diff_time\") < t)\n",
    "\n",
    "#  check which cars have more than 10 infractions\n",
    "dfInfractions = dfSpeeds.groupBy(\"plate\").sum(\"change_in_speed\").withColumnRenamed(\"sum(change_in_speed)\", \"total_infractions\").filter(F.col(\"total_infractions\") >= 10)\n",
    "\n",
    "dfInfractions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analise alternativa\n",
    "\n",
    "dfCalcs.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
